{
   "nbformat_minor" : 0,
   "cells" : [
      {
         "metadata" : {},
         "cell_type" : "markdown",
         "source" : [
            "We need tools for looking at high-dimensional data.\n\nTo get a taste of this, we begin by thinking about **digital humanities.**\n\n"
         ]
      },
      {
         "metadata" : {},
         "source" : [
            "## Some real data\n\n"
         ],
         "cell_type" : "markdown"
      },
      {
         "source" : [
            "Let&rsquo;s load all of the works of Shakespeare.\n\n"
         ],
         "cell_type" : "markdown",
         "metadata" : {}
      },
      {
         "cell_type" : "code",
         "execution_count" : 1,
         "source" : [
            "works = [\"A LOVERâS COMPLAINT\",\n\"A MIDSUMMER NIGHTâS DREAM\",\n\"ALLâS WELL THAT ENDS WELL\",\n\"AS YOU LIKE IT\",\n\"CYMBELINE\",\n\"KING HENRY THE EIGHTH\",\n\"KING JOHN\",\n\"KING RICHARD THE SECOND\",\n\"KING RICHARD THE THIRD\",\n\"LOVEâS LABOURâS LOST\",\n\"MEASURE FOR MEASURE\",\n\"MUCH ADO ABOUT NOTHING\",\n\"PERICLES, PRINCE OF TYRE\",\n\"THE COMEDY OF ERRORS\",\n\"THE FIRST PART OF HENRY THE SIXTH\",\n\"THE FIRST PART OF KING HENRY THE FOURTH\",\n\"THE HISTORY OF TROILUS AND CRESSIDA\",\n\"THE LIFE OF KING HENRY THE FIFTH\",\n\"THE LIFE OF TIMON OF ATHENS\",\n\"THE MERCHANT OF VENICE\",\n\"THE MERRY WIVES OF WINDSOR\",\n\"THE PASSIONATE PILGRIM\",\n\"THE PHOENIX AND THE TURTLE\",\n\"THE RAPE OF LUCRECE\",\n\"THE SECOND PART OF KING HENRY THE FOURTH\",\n\"THE SECOND PART OF KING HENRY THE SIXTH\",\n\"THE TAMING OF THE SHREW\",\n\"THE TEMPEST\",\n\"THE THIRD PART OF KING HENRY THE SIXTH\",\n\"THE TRAGEDY OF ANTONY AND CLEOPATRA\",\n\"THE TRAGEDY OF CORIOLANUS\",\n\"THE TRAGEDY OF HAMLET, PRINCE OF DENMARK\",\n\"THE TRAGEDY OF JULIUS CAESAR\",\n\"THE TRAGEDY OF KING LEAR\",\n\"THE TRAGEDY OF MACBETH\",\n\"THE TRAGEDY OF OTHELLO, MOOR OF VENICE\",\n\"THE TRAGEDY OF ROMEO AND JULIET\",\n\"THE TRAGEDY OF TITUS ANDRONICUS\",\n\"THE TWO GENTLEMEN OF VERONA\",\n\"THE TWO NOBLE KINSMEN\",\n\"THE WINTERâS TALE\",\n\"TWELFTH NIGHT; OR, WHAT YOU WILL\",\n\"VENUS AND ADONIS\"]\n\nfrom urllib.request import urlopen\n\ncorpus = {}\ncurrent = []\nfor line in urlopen('http://www.gutenberg.org/files/100/100-0.txt'):\n    line = line.decode('utf-8')\n    if line.strip() in works:\n        current = corpus[line.strip()] = []\n    current.append( line )\n\nfor work in works:\n    corpus[work] = ''.join(corpus[work])"
         ],
         "outputs" : [],
         "metadata" : {}
      },
      {
         "metadata" : {},
         "source" : [
            "We convert this to some vectors in `n_features`-dimensional space.\n\n"
         ],
         "cell_type" : "markdown"
      },
      {
         "source" : [
            "from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(stop_words = 'english')\nX = vectorizer.fit_transform( [corpus[w] for w in works] )"
         ],
         "execution_count" : 1,
         "outputs" : [],
         "cell_type" : "code",
         "metadata" : {}
      },
      {
         "metadata" : {},
         "source" : [
            "## Similarity\n\n"
         ],
         "cell_type" : "markdown"
      },
      {
         "metadata" : {},
         "source" : [
            "Since we can&rsquo;t immediately visualize vectors in such a\nhigh-dimensional space, it would be helpful to have some idea to\ninspect our data.\n\nOne thing to try is `cosine_similarity` which, with the magic of dot\nproducts, will describe how similar two vectors in our dataset are.\n\n"
         ],
         "cell_type" : "markdown"
      },
      {
         "metadata" : {},
         "cell_type" : "code",
         "outputs" : [],
         "source" : [
            "from sklearn.metrics.pairwise import cosine_similarity\nprint(cosine_similarity(X,X))"
         ],
         "execution_count" : 1
      },
      {
         "source" : [
            "### Homework\n\n"
         ],
         "cell_type" : "markdown",
         "metadata" : {}
      },
      {
         "metadata" : {},
         "source" : [
            "Can you use `matplotlib` to make a nicer plot of this?\n\n"
         ],
         "cell_type" : "markdown"
      },
      {
         "metadata" : {},
         "source" : [
            "## Dimensionality reduction\n\n"
         ],
         "cell_type" : "markdown"
      },
      {
         "cell_type" : "markdown",
         "source" : [
            "It would also help if we had (unsupervised!) methods for reducing\ndimension.  Here is one.\n\n"
         ],
         "metadata" : {}
      },
      {
         "metadata" : {},
         "execution_count" : 1,
         "source" : [
            "from sklearn.decomposition import TruncatedSVD\ntsvd = TruncatedSVD(n_components=2)\ntsvd.fit(X)  \nX2 = tsvd.transform(X)"
         ],
         "outputs" : [],
         "cell_type" : "code"
      },
      {
         "source" : [
            "After applying this transformation, our high-dimensional data is now\ntwo-dimensional!  Thus, we can plot it.\n\n"
         ],
         "cell_type" : "markdown",
         "metadata" : {}
      },
      {
         "cell_type" : "code",
         "outputs" : [],
         "execution_count" : 1,
         "source" : [
            "import matplotlib.pyplot as plt\nplt.scatter( X2[:,0], X2[:,1] )\nfor i, w in enumerate(works):\n    plt.text( X2[i,0], X2[i,1], w )\nplt.show()"
         ],
         "metadata" : {}
      },
      {
         "source" : [
            "You might notice that **The Two Noble Kinsmen** is sitting off by\nitself.  If we look in Wikipedia, we read: &ldquo;Formerly a point of\ncontroversy, the dual attribution is now generally accepted by\nscholarly consensus.&rdquo;  So Shakespeare was not alone in writing **The\nTwo Noble Kinsmen**.\n\n"
         ],
         "cell_type" : "markdown",
         "metadata" : {}
      },
      {
         "source" : [
            "## Multidimensional scaling\n\n"
         ],
         "cell_type" : "markdown",
         "metadata" : {}
      },
      {
         "source" : [
            "There are other ways to embed our high-dimensional data into some\nsmaller space.  Earlier we computed `cosine_similarity(X,X)` as a\nsimilarity matrix.\n\nMultidimensional scaling (usually abbreviated to MDS) transforms a\ndistance matrix into a configuration of vectors.  We found a\nsimilarity matrix, but what we really need is a **dissimilarity**\nmatrix.\n\n"
         ],
         "cell_type" : "markdown",
         "metadata" : {}
      },
      {
         "metadata" : {},
         "execution_count" : 1,
         "source" : [
            "from sklearn.manifold import MDS\nembedding = MDS(n_components=2, dissimilarity='precomputed')\nX_transformed = embedding.fit_transform(1 - cosine_similarity(X,X))\n\nplt.scatter( X_transformed[:,0], X_transformed[:,1] )\nfor i, w in enumerate(works):\n    plt.text( X_transformed[i,0], X_transformed[i,1], w )\nplt.show()"
         ],
         "outputs" : [],
         "cell_type" : "code"
      },
      {
         "cell_type" : "markdown",
         "source" : [
            "### Homework\n\n"
         ],
         "metadata" : {}
      },
      {
         "metadata" : {},
         "source" : [
            "Last week we learned how to make 3-D plots; can you do this with the\ndimensionality reduction code?\n\n"
         ],
         "cell_type" : "markdown"
      }
   ],
   "nbformat" : 4,
   "metadata" : {
      "kernelspec" : {
         "name" : "python3",
         "language" : "python",
         "display_name" : "Python 3"
      },
      "org" : null,
      "language_info" : {
         "version" : "3.5.2",
         "codemirror_mode" : {
            "name" : "ipython",
            "version" : 3
         },
         "name" : "python",
         "nbconvert_exporter" : "python",
         "file_extension" : ".py",
         "mimetype" : "text/x-python",
         "pygments_lexer" : "ipython3"
      }
   }
}
